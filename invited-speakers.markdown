---
title: Invited speakers
---

### [Dan Roth](https://www.cis.upenn.edu/~danroth/)
_University of Pennsylvania and Oracle_

<div style="text-align: left;">
  <a href="/"><img src="/images/dan_roth.jpg" height="200"/></a>
</div>


<details>
<summary>Talk: **On Retrieving & Reasoning LLMs: Myths, Merits, and How to Move Forward**</summary>
The rapid progress made over the last few years in generating linguistically coherent natural language has blurred, in the mind of many, the difference between natural language generation, understanding, knowledge retrieval and use, and the ability to reason with respect to the world.
Nevertheless, reliably and consistently supporting high-level decisions that depend on natural language understanding and heterogenous information retrieval is still difficult, mostly, but not only, since most of these tasks are computationally more complex than language models can support.
I will discuss some of the challenges underlying reasoning and information access and argue that we should exploit what LLMs do well while delegating responsibility to special purpose models and solvers for decision making.
I will present some of our work in this space, focusing on supporting reasoning and information access via Neuro-symbolic methods.
</details>
<details>
<summary>Bio</summary>
Dan Roth is the Eduardo D. Glandt Distinguished Professor at the Department of Computer and Information Science, University of Pennsylvania and the Chief AI Scientist at Oracle.
Until June 2024 Dan was a VP/Distinguished Scientist at AWS AI.
In his role at AWS Roth led over the last three years the scientific effort behind the first-generation Generative AI products from AWS, including Titan Models, Amazon Q efforts, and Bedrock, from inception until they became generally available. 
Dan is a Fellow of the AAAS, ACM, AAAI, and ACL.
In 2017, Dan was awarded the John McCarthy Award; he was recognized for "for major conceptual and theoretical advances in the modeling of natural language understanding, machine learning, and reasoning".
He has published broadly in natural language processing, machine learning, knowledge representation and reasoning, and learning theory, was the Editor-in-Chief of the Journal of Artificial Intelligence Research (JAIR) and has served as a Program Chair and Conference Chair for the major conferences in his research areas.
Roth has been involved in several startups; most recently he was a co-founder and chief scientist of NexLP, a startup that leverages the latest advances in Natural Language Processing, Cognitive Analytics, and Machine Learning in the legal and compliance domains.
NexLP was acquired by Reveal.
Dan received his B.A Summa cum laude in Mathematics from the Technion, Israel and his Ph.D. in Computer Science from Harvard University in 1995.
</details>


### [Vaishak Belle](http://www.vaishakbelle.org/about/)
_University of Edinburgh_

<div style="text-align: left;">
  <a href="/"><img src="/images/vaishak_belle.jpg" height="200"/></a>
</div>

<details>
<summary>Talk: **Reasoning with Large & Small Models: Bridging Symbolic and Neural Approaches**</summary>
This talk explores the intersection of large language models (LLMs) and reasoning systems, with a focus on addressing fundamental challenges in developing correct and reliable systems.
We'll examine our work on augmenting LLMs with external "symbolic executors", creating hybrid architectures that leverage the strengths of both paradigms.
The presentation will then talk about how LLMs represent and manipulate beliefs - standing for interactions with human or artificial users.
We'll also discuss a few considerations for agentic pipelines, and how these sit with the broader paradigm of agent modelling, which has a long history in AI.
We'll preface this development by first briefly reviewing the paradigm of neuro-symbolic AI, and emergent ideas such as loss functions and neural program induction.
</details>
<details>
<summary>Bio</summary>
Dr Vaishak Belle (he/him) is a Chancellorâ€™s Fellow and Reader at the School of Informatics, University of Edinburgh.
He is an Alan Turing Institute Faculty Fellow, a Royal Society University Research Fellow, and a member of the RSE (Royal Society of Edinburgh) Young Academy of Scotland.
He was previously at KU Leuven (Belgium), University of Toronto (Canada), Aachen University of Technology (Germany) and University of Trento (Italy).
At the University of Edinburgh, he directs a research lab on artificial intelligence, specialising in the unification of logic and machine learning, with a recent emphasis on explainability and ethics. He has given research seminars at academic institutions such as MIT and Oxford, tutorials at AI conferences, and talks at venues such as Ars Electronica and the Samsung AI Forum.
He has co-authored close to 120 peer-reviewed articles on AI, at venues such as IJCAI, UAI, AAAI, MLJ, AIJ, JAIR, AAMAS, and along with his co-authors, he has won the Microsoft best paper award at UAI, the Machine learning journal best student paper award at ECML-PKDD, and the Machine learning journal best student paper award at ILP.
In 2014, he received a silver medal by the Kurt Goedel Society.
He has served on the senior program committee/area chair of major AI conferences, co-chaired the ML track at KR, among others, and as PI and CoI secured a grant income of close to 8 million pounds.
Recently, he has consulted with major banks on explainable AI and its impact in financial institutions.
</details>

### [Moa Johansson](https://www.cse.chalmers.se/~jomoa/)
_Chalmers University of Technology_

<div style="text-align: left;">
  <a href="/"><img src="/images/moa_johansson.jpeg" height="200"/></a>
</div>

<details>
<summary>Talk: **PACE: Procedural Abstractions for Communicating Efficiently**</summary>
A central but unresolved aspect of problem-solving in AI is the capability to introduce and use abstractions, something humans excel at.
Work in cognitive science has demonstrated that humans tend towards higher levels of abstraction when engaged in collaborative task-oriented communication, enabling gradually shorter and more information-efficient utterances.
In this talk, I will describe a neuro-symbolic method for introducing such abstractions called PACE.
On the symbolic side, we draw on work from library learning in program synthesis for proposing abstractions.
We combine this with neural methods for communication and reinforcement learning, via a novel use of bandit algorithms for controlling the exploration and exploitation trade-off in introducing new abstractions.
Accepted for CogSci 2025 (oral), preprint: [https://arxiv.org/abs/2409.20120](https://arxiv.org/abs/2409.20120)
</details>
<details>
<summary>Bio</summary>
Moa Johansson is an Associate Professor in the Data Science and AI division at Chalmers University of Technology.
She is interested in neuro-symbolic AI: the combination of neural machine learning methods and symbolic methods from e.g. theorem proving and program synthesis.
Her group works on applications in maths and reasoning, cognitive science, and language.
</details>